---
title: "Computing Smoke Alarm Risk with the AHS + ACS"
author: "Brian Abelson"
date: "June 17, 2015"
output: html_document
---

## Setup
```{r setup, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
rm(list=ls())

# set your working directory here
WD <- '/Users/brianabelson/enigma/public/smoke-alarm-risk'
setwd(WD)

# set where you want the model output to go here
require(ggplot2)
require(reshape2)
require(bigrf)
require(scales)
require(doMC)
require(knitr)
registerDoMC()

# knitr options
opts_chunk$set(
  message=F, echo=F, 
  warning=F, cache=T,
  results='hide',
  fig.height=3,
  fig.width=5
) 
```


```{r run-scripts, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
# include the plot theme
source('rscripts/plot_theme.R')

# clean the ahs data.
source('rscripts/clean_ahs.R')
```

## Explore Missing Data

The AHS does not require that subjects respond to all questions. As a result, there's a lot of missing data. We'll discuss how we deal with it below.

```{r missing-data, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
nrows <- nrow(d)

per_na <- function(x) {
  round(((length(which(is.na(x))) / nrows) * 100), 2)
}

group_per_missing <- function(g){
  vars <- group_to_vars[g][[1]]
  x <- subset(d, select=vars)
  data.frame(group=g, per_missing=mean(apply(x, 2, per_na)))
}
per_missing_by_group <- ldply(groups, group_per_missing)

ggplot(per_missing_by_group, aes(x=reorder(group, per_missing), y=per_missing, label=per_missing)) +
  geom_bar(stat='identity', color=RED, fill=RED) +
  geom_text(size=4) +
  coord_flip() + 
  xlab('Variable group') + 
  ylab('Percent of observations missing') +
  labs(title='Missing Data by Variable Group') + 
  theme_enigma()
```


## Correlations with "smoke"

A simple way to explore what factors are most associated with people who don't have smoke alarms is by computing correlations between the dependent variable and all independent variables.  The following two plots visualize

1. Absolute correlation by variable. 
2. Mean absolute correlation of variable by group.

```{r explore-correlations-1, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}

# remove groups which have a preponderance of missing values
group_to_vars$pvalue <- NULL
group_to_vars$vacancy <- NULL
group_to_vars$qfs1 <- NULL
group_to_vars$rent <- NULL
group_to_vars$lprice <- NULL

vars <- as.character(unlist(group_to_vars))

# remove ids / geo vars / dep. vars.
vars <- vars[7:length(vars)]

calc_correlation_with_y <- function(n, y, abs=F) { 
  c <- round(cor(d[, y], d[, n], use="pairwise.complete.obs"), 3)
  if (abs){
    c <- abs(c)
  }
  return(data.frame(var = n, cor = c))
}

calc_corrlation_per_group_with_y <- function(g, y, abs) { 
    vars <- group_to_vars[g][[1]]
    if (!is.null(vars)) {
      group_cor_d <- ldply(vars, calc_correlation_with_y, y, abs)
      data.frame(group=g, cor=round(mean(na.omit(group_cor_d$cor)), 3)) 
    }
  }

cor_d <- ldply(vars, calc_correlation_with_y, 'smoke')
cor_d <- cor_d[order(cor_d$cor, decreasing=T), ]

ggplot(head(cor_d, 25), aes(x=reorder(var, cor), y=cor, label=cor)) +
  geom_bar(stat='identity', color=TEAL, fill=TEAL) +
  geom_text(size=4) +
  coord_flip() + 
  xlab('Variable') + 
  ylab('Correlation') +
  labs(title='Top 25 correlatied variables with "smoke"') + 
  theme_enigma()

group_cor_d <- ldply(triple_groups, calc_corrlation_per_group_with_y, 'smoke', T)
group_cor_d <- group_cor_d[!is.na(group_cor_d$cor), ]
group_cor_d <- group_cor_d[order(group_cor_d$cor, decreasing=T), ]
ggplot(group_cor_d, aes(x=reorder(group, cor), y=cor, label=cor)) +
  geom_bar(stat='identity', color=TEAL, fill=TEAL) +
  geom_text(size=4) +
  coord_flip() + 
  xlab('Variable group') + 
  ylab('Correlation with smoke') +
  labs(title='Mean absolute correlations with "smoke" by variable group') + 
  theme_enigma()
```

## Variable Selection

```{r variable-selection, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}

# drop groups with too much missing data.
ignore_groups = c('pvalue', 'vacancy', 'zincn', 'qfs1', 'rent', 'lprice')
idx = c()
for (g in ignore_groups) {
  idx <- c(idx, group_to_idx[[g]])
}
d <- d[,-(idx)]

VARS <- c("smoke", 'smsa', "built_1980_to_1989", "built_1960_to_1969", "built_2010_to_later", "built_1990_to_1999", "built_1950_to_1959", "built_1939_or_earlier", "poor_50_to_99", "poor_under_50", "poor_184_to_199", "poor_125_to_149", "poor_100_to_124", "poor_150_to_184", "hhmove_moved_in_1990_to_1999", "hhmove_moved_in_1969_or_earlier", "hhmove_moved_in_2000_to_2009", "hhmove_moved_in_1970_to_1979", "hhmove_moved_in_1980_to_1989", "hhgrad_associates_degree", "hhgrad_7th_or_8th_grade", "hhgrad_9th_grade", "hhgrad_doctorate_degree", "hhgrad_5th_or_6th_grade", "hhgrad_regular_high_school_grad", "hhgrad_bachelors_degree", "hhgrad_1st_2nd_3rd_4th_grade", "hhgrad_11th_grade", "hhgrad_less_than_1st_grade", "hhgrad_12th_grade_no_diploma", "hhspan_yes", "tenure_renter_occupied", "hfuel_wood", "hhrace_hawaiian_pac_isl_only", "hhrace_asian_only", "hhrace_other", "hhrace_black_only", "hhrace_native_am_only", "hhrace_white_only", "mg_yes")
d <- subset(d, select=VARS)
save(d, file='cache/model-data.Rda')
```

## National-level model

We first estimate a single random forest model at the national level. Since only 4% of respondents answered negatively to the question "Do you have a working smoke alarm?", we need to be sensitive to the effects of class imbalance. We first train multiple forests on the same sample of the AHS, incrementing the weighting factor for respondents without smoke alarms.

Assess weighting of dependent variable

```{r test-rf}
# clear memory
rm(list=ls()[which(!ls() %in% c('WD', 'VARS'))])

# load minimal environment.
setwd(WD)
source('rscripts/plot_theme.R')
source('rscripts/model.R')
load(file='cache/model-data.Rda')

# assess effect of class weights on errors.
o <- rf_classwts(d, ntree=30, sampsize=50000, weights=seq(1,31, 5), trace=0)
rf_classwts_plot(o, optimal=21)
```

Cross validation

```{r train-model, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
res <- rf_cross_validate(d, ntree=30, split_per=0.6, 
                         trace=0, classwts=c(1,20), impute=T)
roc_curve(res$actual, as.numeric(res$probs), title='ROC Curve for Random Forest')
cat("Training Errors:\n")
res$train_err 
cat("Testing Errors:\n")
res$test_err 
```

Plot a histogram of the computed probabilities

```{r prob-histogram, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
p <- data.frame(x=res$probs)
ggplot(p, aes(x=x)) + 
  geom_histogram(color="white", fill=BLUE, binwidth=0.04) +
  theme_enigma() + 
  ylab('Count') + 
  xlab('Estimated Probabilities') + 
  labs(title='Distribution of smoke alarm risk probabilities')
```

Train on the entire AHS

```{r final-model, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
natl_model <- rf_estimate(d, importance=T, classwts = c(1, 20), 
                   ntree=200, trace=1)
save(natl_model, file='cache/natl-model.Rda')
```

Variable Importance 

```{r var-importance, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
rf_imp_plot(natl_model$imp, 
            title = "Variable importance.")
```

## Generating the MSA-level models

In order to account for regional-level variation, we model risk for each MSA.  In order to accomplish this, we needed to select particular MSAs which would have enough data to model.

```{r compute-msa-stats, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
# clear memory
rm(list=ls()[which(!ls() %in% c('WD', 'VARS'))])

# load minimal environment.
setwd(WD)
require(plyr)
source('rscripts/plot_theme.R')
source('rscripts/model.R')
load(file='cache/model-data.Rda')

# compute assessments for msas
assess_msas <- function(x) {
  ddply(x, 'smsa', summarize, 
               n=length(smoke), 
               n_negative=length(which(smoke==1)),
               per_negative=length(which(smoke==1))/length(smoke))
}
msa_t <- assess_msas(d)
msa_t <- msa_t[-(which(msa_t$smsa=="9999")),]
msa_t$score <- 1 - normscore(msa_t$per_negative, to=c(1,0))^2
```

A histogram of number of respondents per MSA.

```{r compute-msa-stats-histogram, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
ggplot(msa_t, aes(x=n)) + 
  geom_histogram(binwidth=100, color="white", fill=RED) + 
  labs(title='Total respondents per MSA') + 
  xlab('Number of respondents') + 
  ylab('Count') + 
  theme_enigma()
```

A histogram of respondents without smoke alarms  MSA.

```{r compute-msa-stats-histogram-neg, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
ggplot(msa_t, aes(x=n_negative)) + 
  geom_histogram(binwidth=20, color="white", fill=RED) + 
  labs(title='Respondents w/o alarms per MSA') + 
  xlab('Number of respondents w/o alarms') + 
  ylab('Count') + 
  theme_enigma()
```

A scatterplot of, per MSA,  the percentage of respondents without smoke alarms by the 
total number of respondents.

```{r compute-msa-stats-scatter, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
ggplot(msa_t, aes(x=n, y=per_negative)) + 
  geom_point(color=RED, alpha=0.5) + 
  xlab('Respondents') + 
  ylab('% Without Smoke Alarms') + 
  labs(title='Assessment of MSA data quality') + 
  theme_enigma()
```

Select MSAs with enough data.

```{r select-msas, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
MIN_MSA_OBS <- 2000
TEST_MSA <- '7360'
GOOD_MSAS <- as.character(msa_t$smsa[msa_t$n>= MIN_MSA_OBS])
write(GOOD_MSAS, 'data/msas.txt')
cat('Selected', length(GOOD_MSAS), 'out of', nrow(msa_t), "MSAs")
cat('Dropped', (1-round(length(GOOD_MSAS) / nrow(msa_t), 4)) * 100, '% of MSAs')
```

Train MSA models.

```{r rf-msas, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}

# a function for weighting an msa model 
# by it's metrics
weight_msa <- function(b, f) {
  return(b + (b *  f))
}

# a function for computing risk coefficients 
# for an individual msa
estimate_msa <- function(msa, ntree, base, offset) { 
  
  d_m_t <- msa_t[which(msa_t$smsa==msa),]
  d_m <- d[d$smsa==msa,]

  # factor the model's weight based on the ratio of residents w/o smoke alarms
  f <- (1-d_m_t$score) - offset
  wt <- weight_msa(base, f)
  classwts <- c(1, wt)

  cat('\nTraining MSA', msa, 'with weight', 
      classwts[2], ', factor', f, ', score', d_m_t$score, 
      ', and offset', offset, '.\n\n')
  
  train <- rf_estimate(d_m, classwts = classwts, 
                   ntree=ntree, trace=0)
  metrics <- data.frame(d_m_t, train$train_err, weight=wt)
  list(metrics=metrics, m=train$m)
}

estimate_msas <- function(msas, ntree, base, offset) {
  
  res <- llply(msas, estimate_msa, ntree, base, offset)
  names(res) <- msas 
  return(res)
}

# train + save models

res <- estimate_msas(GOOD_MSAS, ntree=100, 
                            base = 32, offset=0.8)

# BASE: 22, OFFSET=0.8
# Mean false positve rate 0.5849392 
# Mean error rate for MSA models: 0.2823388 
# 
# BASE: 30, OFFSET=0.8
# Mean false positve rate for MSA models: 0.4904784 
# Mean error rate for MSA models: 0.3768944 

msa_models <- llply(res, function(x) { x$m })
save(msa_models, file='cache/msa-models.Rda')
msa_metrics <- ldply(res, function(x) { x$metrics })
save(msa_metrics, file='cache/msa-metrics.Rda')
rm(msa_models, res)
```

Assess the predictive power of MSA models relative to their sample characteristics.

```{r rf-msas-metrics, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
mean_lacks_alarm_err <- mean(msa_metrics$train_lacks_alarm_err)
mean_err <- mean(msa_metrics$train_err)
cat('Mean false positve rate for MSA models:', mean_lacks_alarm_err, '\n')
cat('Mean error rate for MSA models:', mean_err, '\n')

# plot error rate by sample size.
ggplot(msa_metrics, aes(y=train_lacks_alarm_err, x=n_negative)) + 
  geom_point(color=TEAL, size=3, alpha=0.6) + 
  stat_smooth(method="lm", se=T, color=RED, alpha=0.3) + 
  ylab('% False positives') + 
  xlab('Respondents without alarms') + 
  ylim(0,1) +
  labs(title='MSA-level false positives by respondents without alarms') +
  theme_enigma()

# computed class weight
ggplot(msa_metrics, aes(y=weight, x=n_negative)) + 
  geom_point(color=TEAL, size=3, alpha=0.6) + 
  stat_smooth(method="lm", se=T, color=RED, alpha=0.3) + 
  ylab('Computed class weight') + 
  xlab('Respondents without alarms') + 
  labs(title='MSA-level errors by computed class weight') +
  theme_enigma()

# plot error rate by sample size.
ggplot(msa_metrics, aes(y=train_err, x=n)) + 
  geom_point(color=TEAL, size=3, alpha=0.6) + 
  stat_smooth(method="lm", se=T, color=RED, alpha=0.3) + 
  ylab('Error rate') + 
  xlab('Respondents.') + 
  ylim(0, 1) + 
  labs(title='MSA-level errors by total respondents') +
  theme_enigma()

```

## Generating the risk scores

Now that we have our multi-leveled coefficients, we need to set about applying them to ACS data to generate risk scores for each census block group. 

Since we've already comprehensively mapped variables between the two datasets, this process is relatively straightforward.

```{r read-in-acs, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
rm(list=ls()[which(!ls() %in% c('WD', 'VARS'))])
# load minimal environment.
setwd(WD)
source('rscripts/model.R')
source('rscripts/plot_theme.R')
source('rscripts/clean_acs.R')
load(file='cache/natl-model.Rda')
load(file='cache/msa-models.Rda')
load(file='cache/msa-metrics.Rda')
```

Compute national risk scores for the ACS.

```{r score-acs, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}

# hack
acs_bg$smoke <- NA
bg_geoid <- acs_bg$bg_geoid
acs_bg <- subset(acs_bg, select=VARS)

# apply transformation to acs variables
acs_bg_t <- apply(acs_bg[,3:ncol(acs_bg)], 2, function(x) { 
  return(normscore(log10(x + 0.05)))
  })
acs_bg_t <- cbind(acs_bg[,1:2], acs_bg_t)

# compute block-group probabilities
natl <- rf_predict(natl_model$m, d=acs_bg_t, impute=F, trace=0)

# initally format output
output <- data.frame(bg_geoid=bg_geoid, smsa=acs_bg$smsa, 
                natl_score=natl$probs, msa_score=NA, stringsAsFactors = F)
# cleanup
rm(bg_geoid, natl, natl_model)
```

Compute MSA-level risk scores for the ACS.

```{r score-msa-acs, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}

for (msa in names(msa_models)) {
    cat('Scoring MSA', msa, '... \n')
    m <- msa_models[msa][[1]]
    idx <- which(acs_bg$smsa==msa)
    d <- acs_bg[idx,]
    if (nrow(d)) { 
      msa_p <- rf_predict(m, d=d, impute=F, trace=0)
      output$msa_score[idx] <- msa_p$probs
    }
}
```

Merge scores

```{r score-merge, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
idx <- !is.na(output$msa_score)
msa_o <- output[idx, ]
natl_o <- output[!idx, ]
msa_o$smoke_alarm_risk <- rowMeans(output[idx, c('msa_score', 'natl_score')])
natl_o$smoke_alarm_risk <- as.numeric(output[!idx, 'natl_score'])
output <- rbind(msa_o, natl_o)
```

Assess scores.

```{r score-metrics, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}

# plot a histogram of the computed scores
ggplot(output, aes(x=smoke_alarm_risk)) + 
  geom_histogram(aes(y=..density..), color="white", fill=BLUE, binwidth=0.04) +
  geom_density(color=RED) + 
  theme_enigma() + 
  ylab('Density') + 
  xlab('National smoke alarm risk') + 
  labs(title='National smoke alarm risk per census block group')

# distribution of MSA scores.
ggplot(output, aes(x=msa_score)) + 
  geom_histogram(aes(y=..density..), color="white", fill=BLUE, binwidth=0.04) +
  geom_density(color=RED) + 
  xlab('MSA-level smoke alarm risk') +
  ylab('Density') + 
  labs(title='MSA-level smoke alarm risk per census block group.') + 
  theme_enigma()

ggplot(output, aes(x=natl_score, y=msa_score)) + 
  geom_point(color='BLUE', alpha=0.03) + 
  stat_smooth(method="lm", se=T, color=RED, alpha=0.3) + 
  xlab('National-level score') + 
  ylab('MSA-level score') + 
  labs(title='National vs. MSA-level scores') +
  theme_enigma() 
```

## Formatting the output.

In order to give a better indication of whether a block group is at-risk for fatalities from fires, we also include an indicator for the percentage of the population that is under the age of 5 or over the age of 65 for each block group. We also include the total population and population density to filter out block groups without sufficient inhabitants to compute reliable scores.

```{r format-output, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
at_risk <- as.data.frame(fread('data/acs-bg-at-risk-population.csv'))
pop <- as.data.frame(fread('data/acs-bg-population.csv'))
output <- join(output, at_risk, by='bg_geoid')
output <- join(output, pop, by='bg_geoid')
output <- join(output, pop_density, by='bg_geoid')
write.csv(output, 'data/smoke-alarm-risk-scores.csv', row.names=F, na="")
cat('Smoke alarm risk scores written to', 'data/smoke-alarm-risk-scores.csv')
```

